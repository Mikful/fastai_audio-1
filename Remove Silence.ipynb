{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Silence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I show how to cut the audio up based on whether there is sound in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Notebook settings\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please makes sure you have the [fastai-audio](https://github.com/mogwai/fastai-audio) repo installed in the `fastai_audio` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'exp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a49a44009ce0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mexp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'exp'"
     ]
    }
   ],
   "source": [
    "from exp import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = AudioData.load('./Right_whale.wav')\n",
    "sr = ad.sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this we can get a better idea of the samples inside the audio track and what ranges we need to filter out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(ad):\n",
    "    print(f'Min: {ad.sig.min()}')\n",
    "    print(f'Max: {ad.sig.max()}')\n",
    "    print(f'Mean: {ad.sig.mean()}')\n",
    "    print(f'std: {ad.sig.std()}')\n",
    "    print(f'Shape: {ad.sig.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = AudioItem(ad)\n",
    "plt.plot(s.data.sig)\n",
    "s.hear()\n",
    "stats(ad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering by range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the above roughly what ranges we're interested in so we'll filter by that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = s.data.sig.clone()\n",
    "sig[(sig < .03) & (sig > -.03)] = 0 \n",
    "wos = AudioItem(AudioData(sig, s.data.sr))\n",
    "plt.plot(sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you can see that the main calls have been selected but the audio sounds strange without a bit of padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wos.hear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we know there is only one call in the file we could just slam it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = s.data.sig[(wos.data.sig != 0)]\n",
    "AudioItem(AudioData(sig, sr)).hear()\n",
    "plt.plot(sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sounds a bit funky though ;) \n",
    "\n",
    "Lets cut out the parts we're interested in and add some padding to them\n",
    "\n",
    "We'll create samples as long as we find frequencies within the padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "groups = []\n",
    "looking = 0\n",
    "c = 0\n",
    "actual = s.data.sig\n",
    "padding = int(len(actual)*0.015) # This is the magic number\n",
    "\n",
    "for index, i in enumerate(wos.data.sig):\n",
    "    if looking: \n",
    "        c+=1\n",
    "        if index - looking >= padding:\n",
    "            groups.append(actual[index-c-padding: index])\n",
    "            c = 0\n",
    "            looking = False\n",
    "            continue\n",
    "    \n",
    "\n",
    "print('Number of calls found:', len(groups))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we have it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ad.sig.shape)\n",
    "def split_by_silence(ad:AudioData, thresholds=None, pad_ms=200)->[AudioData]:\n",
    "    actual = ad.sig.clone()\n",
    "    sr = ad.sr\n",
    "    if not thresholds: thresholds = (actual < .03) & (actual > -.03)\n",
    "    \n",
    "    sig = actual.clone()\n",
    "    sig[thresholds] = 0\n",
    "    \n",
    "    groups = []\n",
    "    looking = 0\n",
    "    c = 0\n",
    "    padding = int(pad_ms/1000*sr) # This is the magic number\n",
    "\n",
    "    for index, i in enumerate(sig):\n",
    "        if looking: \n",
    "            c+=1\n",
    "            if index - looking >= padding:\n",
    "                nd = actual[index-c-padding: index]\n",
    "                groups.append(AudioData(nd, sr))\n",
    "                c = 0\n",
    "                looking = False\n",
    "                continue\n",
    "        \n",
    "        if not i.equal(torch.tensor(.0)):\n",
    "            looking = index\n",
    "    \n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = split_by_silence(ad, pad_ms=250)\n",
    "print(len(groups))\n",
    "for i in range(5):\n",
    "    d = groups[i]\n",
    "    plt.plot(d.sig)\n",
    "    plt.show()\n",
    "#     Optionally to save the audio:\n",
    "#     torchaudio.save('whale'+str(i)+'.wav', groups[i], sr )\n",
    "    AudioItem(d).hear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
